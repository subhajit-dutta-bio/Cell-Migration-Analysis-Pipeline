{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **🧬 Complete Cell Migration Analysis Pipeline**"
      ],
      "metadata": {
        "id": "PrrYcoI16oi1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **👨‍💻 Author Details**\n",
        "\n",
        "# **Subhajit Dutta, M.Sc.**\n",
        "\n",
        "Institute of Cell Biology and Tumor Research (IBMZ),\n",
        "University Medical Center Hamburg-Eppendorf (UKE)\n",
        "\n",
        "University of Hamburg, Germany\n",
        "\n",
        "Contact: dsubhajit.edu@gmail.com"
      ],
      "metadata": {
        "id": "r2DHv-ar6U20"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **📖 Introduction**\n",
        "\n",
        "This notebook provides a comprehensive, interactive, and reproducible pipeline for analyzing cell migration datasets generated by TrackMate (an open-source tracking tool in Fiji/ImageJ).\n",
        "\n",
        "TrackMate detects and tracks individual cells or particles across time-lapse microscopy images. It outputs CSV files containing positional coordinates (POSITION_X, POSITION_Y, POSITION_Z) and time/frame information (FRAME).\n",
        "Our pipeline processes these CSV files to extract important biophysical and migratory parameters, visualize behavior over time, and statistically compare experimental conditions.\n",
        "\n",
        "This tool is particularly useful for comparing different treatments, genetic modifications, or environmental conditions affecting cell motility."
      ],
      "metadata": {
        "id": "zwQmV2c65SPl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**🛠️ Measurements and Features Calculated**\n",
        "\n",
        "For each track (individual cell trajectory), the following features are extracted:\n",
        "\n",
        "Mean Speed (μm/min): Average movement speed over time.\n",
        "\n",
        "Total Displacement (μm): Straight-line distance from start to end.\n",
        "\n",
        "Total Distance Travelled (μm): Cumulative path length.\n",
        "\n",
        "Directionality (ratio): Straightness of the path (displacement / total distance).\n",
        "\n",
        "Track Duration (frames): Time from first to last detection.\n",
        "\n",
        "Asphericity: Shape irregularity of the trajectory (based on covariance of x and y).\n",
        "\n",
        "Mean Square Displacement (MSD): Time-lagged spatial exploration behavior.\n",
        "\n",
        "Mean Turning Angle (radians): Angular deviation between steps.\n",
        "\n",
        "Velocity Vectors: Instantaneous movement vectors between frames.\n",
        "\n",
        "Displacement Angle: Final angle between start and end points.\n",
        "\n",
        "Additionally:\n",
        "\n",
        "Instantaneous Speed Plot (per condition)\n",
        "\n",
        "Directionality Polar Plot and Animated Rose Plots\n",
        "\n",
        "Statistical comparisons between groups (auto-selected tests based on normality/homogeneity)."
      ],
      "metadata": {
        "id": "cRU6OA9p5hc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **🧪 Usage Guidelines**\n",
        "\n",
        "*Requirements*\n",
        "\n",
        "Input data: TrackMate exported ***spot .csv files*** (one or multiple files per condition).\n",
        "\n",
        "The notebook will automatically guide you interactively:\n",
        "\n",
        "Upload your CSV files to Colab.\n",
        "\n",
        "Specify the number of experimental conditions.\n",
        "\n",
        "Assign files to each condition.\n",
        "\n",
        "Run the full pipeline (either all tracks or equal number of tracks) to compute features, create plots, movies, and perform statistical analysis.\n",
        "\n",
        "Outputs will be packaged into a downloadable .zip file containing:\n",
        "\n",
        "CSV summary of extracted features\n",
        "\n",
        "CSV of statistical test results\n",
        "\n",
        "Box plots, strip plots, and rose plots (both raw and statistically annotated)\n",
        "\n",
        "Animated MP4 movies of speed and directionality evolution"
      ],
      "metadata": {
        "id": "vsCpVQY_5sid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**📜 Usage Policy**\n",
        "\n",
        "Free for academic use.\n",
        "\n",
        "If you use this notebook or its output in your research:\n",
        "\n",
        "Acknowledge its usage in your Methods section.\n",
        "\n",
        "Cite the corresponding publication if a paper based on this pipeline appears (forthcoming).\n",
        "\n",
        "Disclaimer:\n",
        "\n",
        "The author is not responsible for any errors, misinterpretations, or modifications made to this pipeline after download.\n",
        "\n",
        "Users are encouraged to validate outputs against their experimental expectations."
      ],
      "metadata": {
        "id": "iyCDOZMK6L9E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_UiuCvM_JVB"
      },
      "outputs": [],
      "source": [
        "######################## COMPLETE CELL MIGRATION ANALYSIS FOR ALL SPOTS ########################\n",
        "print(\"Starting interactive cell migration analysis...\")\n",
        "\n",
        "# Install required packages\n",
        "!pip install -q umap-learn seaborn>=0.12 scikit-posthocs ipywidgets\n",
        "!apt-get install -qq ffmpeg > /dev/null\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "import scikit_posthocs as sp\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "import warnings\n",
        "from google.colab import files\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration\n",
        "data_dir = '/content'\n",
        "output_dir = '/content/output'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ==================== INTERACTIVE SETUP ====================\n",
        "print(\"\\n=== Condition Setup ===\")\n",
        "print(\"1. Specify number of experimental conditions\")\n",
        "print(\"2. Name each condition\")\n",
        "print(\"3. Select CSV files for each condition from uploaded files\\n\")\n",
        "\n",
        "# Get list of available CSV files\n",
        "available_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
        "\n",
        "# Widget for condition setup\n",
        "condition_count = widgets.IntText(\n",
        "    value=min(3, len(available_files)) if available_files else 1,\n",
        "    description='Number of conditions:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "condition_widgets = []\n",
        "generate_btn = widgets.Button(description=\"Generate Input Fields\")\n",
        "run_btn = widgets.Button(description=\"Run Analysis\", button_style='success')\n",
        "\n",
        "def generate_fields(b):\n",
        "    global condition_widgets\n",
        "    clear_output()\n",
        "    condition_widgets = []\n",
        "\n",
        "    display(condition_count)\n",
        "\n",
        "    for i in range(condition_count.value):\n",
        "        name_widget = widgets.Text(\n",
        "            description=f'Condition {i+1} Name:',\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "\n",
        "        # Create dropdown with available CSV files\n",
        "        file_widget = widgets.SelectMultiple(\n",
        "            options=available_files,\n",
        "            description=f'Select CSV(s) for Condition {i+1}:',\n",
        "            disabled=False,\n",
        "            style={'description_width': 'initial'},\n",
        "            layout=widgets.Layout(width='50%')  # optional, makes it wider\n",
        "        )\n",
        "\n",
        "\n",
        "        condition_widgets.append((name_widget, file_widget))\n",
        "        display(name_widget, file_widget)\n",
        "\n",
        "    display(run_btn)\n",
        "\n",
        "generate_btn.on_click(generate_fields)\n",
        "display(condition_count, generate_btn)\n",
        "\n",
        "# ==================== ANALYSIS FUNCTIONS ====================\n",
        "def save_plot(fig, name, subfolder):\n",
        "    if not hasattr(fig, 'savefig'):\n",
        "        fig = plt.gcf()\n",
        "    path = os.path.join(output_dir, subfolder, name)\n",
        "    fig.savefig(path, bbox_inches='tight', dpi=300)\n",
        "    plt.close(fig)\n",
        "\n",
        "def compute_track_features(track_df):\n",
        "    track_df = track_df.sort_values('FRAME')\n",
        "    if len(track_df) < 2:\n",
        "        return None\n",
        "\n",
        "    # Clean and convert numeric columns\n",
        "    for col in ['POSITION_X','POSITION_Y','POSITION_Z','FRAME']:\n",
        "        if col in track_df.columns:\n",
        "            track_df[col] = pd.to_numeric(track_df[col], errors='coerce')\n",
        "            if col in ['POSITION_X','POSITION_Y','FRAME']:\n",
        "                track_df = track_df.dropna(subset=[col])\n",
        "    if len(track_df) < 2:\n",
        "        return None\n",
        "\n",
        "    # Position and time data\n",
        "    x = track_df['POSITION_X'].values.astype(float)\n",
        "    y = track_df['POSITION_Y'].values.astype(float)\n",
        "    z = track_df.get('POSITION_Z', np.zeros(len(x))).astype(float)\n",
        "    t = track_df['FRAME'].values.astype(float)\n",
        "\n",
        "    # Calculate displacements and speeds\n",
        "    delta_x = np.diff(x)\n",
        "    delta_y = np.diff(y)\n",
        "    delta_z = np.diff(z)\n",
        "    delta_t = np.diff(t).astype(float)\n",
        "    delta_t[delta_t == 0] = np.nan\n",
        "\n",
        "    step_dist = np.sqrt(delta_x**2 + delta_y**2 + delta_z**2)\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter('ignore')\n",
        "        step_speed = step_dist / delta_t\n",
        "\n",
        "    valid = ~np.isnan(step_speed)\n",
        "    speeds = step_speed[valid]\n",
        "    if len(speeds)==0:\n",
        "        return None\n",
        "\n",
        "    # Velocity and direction calculations\n",
        "    velocity_vectors = np.column_stack((delta_x, delta_y)) / delta_t[:, None]\n",
        "    step_angles = np.arctan2(velocity_vectors[:, 1], velocity_vectors[:, 0])\n",
        "    turning_angles = np.abs(np.diff(step_angles))\n",
        "    turning_angles = np.where(turning_angles > np.pi, 2*np.pi - turning_angles, turning_angles)\n",
        "\n",
        "    # Core metrics\n",
        "    mean_speed = np.nanmean(speeds)\n",
        "    displacement = np.sqrt((x[-1]-x[0])**2 + (y[-1]-y[0])**2)\n",
        "    total_distance = np.nansum(step_dist[valid])\n",
        "    directionality = displacement / total_distance if total_distance > 0 else np.nan\n",
        "\n",
        "    # MSD calculation\n",
        "    time_lags = np.unique(t[1:][valid] - t[0])\n",
        "    msd = np.zeros(len(time_lags))\n",
        "    for i, lag in enumerate(time_lags):\n",
        "        time_pairs = t[:, None] - t\n",
        "        mask = (time_pairs == lag) & (np.triu(np.ones_like(time_pairs, dtype=bool), k=1))\n",
        "        dx = x[:, None] - x\n",
        "        dy = y[:, None] - y\n",
        "        diffs = (dx**2 + dy**2)[mask]\n",
        "        msd[i] = np.mean(diffs) if len(diffs) > 0 else np.nan\n",
        "\n",
        "    # Shape metrics\n",
        "    xy = np.column_stack((x, y))\n",
        "    if len(xy) > 1:\n",
        "        cov = np.cov(xy.T)\n",
        "        eigvals = np.linalg.eigvals(cov)\n",
        "        eigvals = sorted(eigvals, reverse=True)\n",
        "        asphericity = (eigvals[0] - eigvals[1])**2 / sum(eigvals)**2 if sum(eigvals) > 0 else np.nan\n",
        "    else:\n",
        "        asphericity = np.nan\n",
        "\n",
        "    # Final displacement angle\n",
        "    dx = x[-1] - x[0]\n",
        "    dy = y[-1] - y[0]\n",
        "    displacement_angle = np.arctan2(dy, dx) if (dx != 0 or dy != 0) else np.nan\n",
        "\n",
        "    return {\n",
        "        'track_id': track_df['TRACK_ID'].iloc[0],\n",
        "        'condition': track_df['condition'].iloc[0],\n",
        "        'mean_speed': mean_speed,\n",
        "        'displacement': displacement,\n",
        "        'total_distance': total_distance,\n",
        "        'directionality': directionality,\n",
        "        'asphericity': asphericity,\n",
        "        'duration': t[-1] - t[0],\n",
        "        'mean_x': np.mean(x),\n",
        "        'mean_y': np.mean(y),\n",
        "        'step_speeds': speeds,\n",
        "        'step_angles': step_angles,\n",
        "        'turning_angles': turning_angles,\n",
        "        'times': t[1:][valid],\n",
        "        'velocity_vectors': velocity_vectors,\n",
        "        'displacement_angle': displacement_angle,\n",
        "        'mean_square_displacement': np.nanmean(msd),\n",
        "        'mean_displacement': np.nanmean(step_dist[valid]),\n",
        "        'track_straightness': directionality,\n",
        "        'mean_turning_angle': np.nanmean(turning_angles) if len(turning_angles) > 0 else np.nan\n",
        "    }\n",
        "\n",
        "def create_instantaneous_speed_movie(features_df, color_palette, output_dir):\n",
        "    print(\"Creating speed movie...\")\n",
        "    condition_data = {}\n",
        "    max_speed, min_speed = 0, float('inf')\n",
        "\n",
        "    for condition in color_palette:\n",
        "        all_times, all_speeds = [], []\n",
        "        for _, row in features_df[features_df['condition'] == condition].iterrows():\n",
        "            all_times.extend(row['times'])\n",
        "            all_speeds.extend(row['step_speeds'])\n",
        "\n",
        "        df = pd.DataFrame({'time': all_times, 'speed': all_speeds})\n",
        "        df = df.groupby('time')['speed'].mean().reset_index()\n",
        "        df['smoothed_speed'] = gaussian_filter1d(df['speed'], sigma=1.5) if len(df) > 1 else df['speed']\n",
        "        condition_data[condition] = df\n",
        "        max_speed = max(max_speed, df['speed'].max())\n",
        "        min_speed = min(min_speed, df['speed'].min())\n",
        "\n",
        "    all_times = np.concatenate([df['time'] for df in condition_data.values()])\n",
        "    time_points = np.linspace(min(all_times), max(all_times), 150)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 8), dpi=300)\n",
        "    plt.xlabel('Time (frames)')\n",
        "    plt.ylabel('Speed (μm/min)')\n",
        "    plt.title('Instantaneous Speed vs Time')\n",
        "\n",
        "    raw_lines, smooth_lines, markers = {}, {}, {}\n",
        "    for cond, color in color_palette.items():\n",
        "        raw_lines[cond], = ax.plot([], [], lw=1.5, color=color, alpha=0.25)\n",
        "        smooth_lines[cond], = ax.plot([], [], lw=2.5, color=color, alpha=0.9, label=cond)\n",
        "        markers[cond], = ax.plot([], [], 'o', color=color, markersize=8)\n",
        "\n",
        "    y_padding = (max_speed - min_speed) * 0.2\n",
        "    ax.set_ylim(max(0, min_speed - y_padding), max_speed + y_padding)\n",
        "    ax.set_xlim(min(all_times), max(all_times))\n",
        "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "    def animate(i):\n",
        "        current_time = time_points[i]\n",
        "        for cond, df in condition_data.items():\n",
        "            mask = df['time'] <= current_time\n",
        "            times = df['time'][mask]\n",
        "            if len(times) > 0:\n",
        "                raw_lines[cond].set_data(times, df['speed'][mask])\n",
        "                smooth_lines[cond].set_data(times, df['smoothed_speed'][mask])\n",
        "                if times.iloc[-1] >= current_time:\n",
        "                    markers[cond].set_data([current_time], [df['smoothed_speed'][mask].iloc[-1]])\n",
        "        return list(raw_lines.values()) + list(smooth_lines.values()) + list(markers.values())\n",
        "\n",
        "    ani = animation.FuncAnimation(fig, animate, frames=len(time_points), interval=30, blit=True)\n",
        "    output_path = os.path.join(output_dir, 'Without Stats', 'instantaneous_speed_movie.mp4')\n",
        "    ani.save(output_path, writer='ffmpeg', dpi=300, bitrate=5000)\n",
        "    plt.close()\n",
        "\n",
        "def create_directionality_movie(features_df, palette, output_dir):\n",
        "    print(\"Creating directionality movie...\")\n",
        "    def rose_plot(ax, angles, color, n_bins=24):\n",
        "        hist, bins = np.histogram(angles, bins=n_bins, range=(-np.pi,np.pi))\n",
        "        widths = np.diff(bins)\n",
        "        ax.bar(bins[:-1], hist, width=widths, bottom=0, color=color, alpha=0.7, edgecolor='black', align='edge')\n",
        "\n",
        "    cond_data = {}\n",
        "    for cond in palette:\n",
        "        times, angs = [], []\n",
        "        for _, row in features_df[features_df['condition']==cond].iterrows():\n",
        "            if not np.isnan(row['displacement_angle']):\n",
        "                times.append(row['times'][-1])\n",
        "                angs.append(row['displacement_angle'])\n",
        "        cond_data[cond] = pd.DataFrame({'time':times,'angle':angs})\n",
        "\n",
        "    all_t = np.unique(np.concatenate([d['time'] for d in cond_data.values()]))\n",
        "    time_pts = np.linspace(all_t.min(), all_t.max(), 100)\n",
        "\n",
        "    fig = plt.figure(figsize=(4*len(palette),4), dpi=300)\n",
        "    axes = [fig.add_subplot(1,len(palette),i+1, projection='polar') for i in range(len(palette))]\n",
        "    for ax in axes:\n",
        "        ax.set_theta_zero_location('E')\n",
        "        ax.set_theta_direction(-1)\n",
        "\n",
        "    def animate(i):\n",
        "        t = time_pts[i]\n",
        "        for ax,(cond,color) in zip(axes, palette.items()):\n",
        "            ax.clear()\n",
        "            ax.set_theta_zero_location('E')\n",
        "            ax.set_theta_direction(-1)\n",
        "            ax.set_title(cond, pad=20)\n",
        "            past = cond_data[cond][cond_data[cond]['time']<=t]\n",
        "            if not past.empty:\n",
        "                rose_plot(ax, past['angle'].values, color)\n",
        "        return axes\n",
        "\n",
        "    ani = animation.FuncAnimation(fig, animate, frames=len(time_pts), interval=100, blit=False)\n",
        "    out = os.path.join(output_dir,'Without Stats','directionality_rose_movie.mp4')\n",
        "    ani.save(out, writer='ffmpeg', dpi=300, bitrate=5000)\n",
        "    plt.close(fig)\n",
        "\n",
        "def run_statistical_tests(features_df, test_method='auto'):\n",
        "    print(\"Running statistical tests...\")\n",
        "    statistical_results = []\n",
        "    features_to_analyze = ['mean_speed', 'directionality', 'asphericity', 'duration',\n",
        "                         'mean_square_displacement', 'mean_displacement',\n",
        "                         'track_straightness', 'mean_turning_angle']\n",
        "    conditions = features_df['condition'].unique()\n",
        "\n",
        "    if len(conditions) < 2:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    for feature in features_to_analyze:\n",
        "        groups = [features_df[features_df['condition'] == c][feature].dropna().values for c in conditions]\n",
        "        valid_groups = [g for g in groups if len(g) > 0]\n",
        "        if len(valid_groups) < 2:\n",
        "            continue\n",
        "\n",
        "        selected_test = test_method\n",
        "        if test_method == 'auto':\n",
        "            normal = all(len(g) > 3 and stats.shapiro(g)[1] > 0.05 for g in valid_groups)\n",
        "            equal_var = stats.levene(*valid_groups).pvalue > 0.05 if normal else False\n",
        "\n",
        "            if len(conditions) == 2:\n",
        "                selected_test = 't-test' if (normal and equal_var) else 'welch' if normal else 'mannwhitney'\n",
        "            else:\n",
        "                selected_test = 'anova' if (normal and equal_var) else 'kruskal'\n",
        "\n",
        "        try:\n",
        "            if selected_test in ['t-test', 'welch']:\n",
        "                result = stats.ttest_ind(*valid_groups[:2], equal_var=(selected_test == 't-test'))\n",
        "                statistical_results.append({\n",
        "                    'feature': feature,\n",
        "                    'test_method': selected_test.upper(),\n",
        "                    'condition1': conditions[0],\n",
        "                    'condition2': conditions[1],\n",
        "                    'p_value': result.pvalue,\n",
        "                    'significance': '***' if result.pvalue < 0.001 else '**' if result.pvalue < 0.01 else '*' if result.pvalue < 0.05 else ''\n",
        "                })\n",
        "            elif selected_test == 'mannwhitney':\n",
        "                result = stats.mannwhitneyu(*valid_groups[:2])\n",
        "                statistical_results.append({\n",
        "                    'feature': feature,\n",
        "                    'test_method': selected_test.upper(),\n",
        "                    'condition1': conditions[0],\n",
        "                    'condition2': conditions[1],\n",
        "                    'p_value': result.pvalue,\n",
        "                    'significance': '***' if result.pvalue < 0.001 else '**' if result.pvalue < 0.01 else '*' if result.pvalue < 0.05 else ''\n",
        "                })\n",
        "            elif selected_test == 'anova':\n",
        "                _, p_value = stats.f_oneway(*valid_groups)\n",
        "                posthoc = sp.posthoc_tukey(features_df, val_col=feature, group_col='condition')\n",
        "                for i in range(len(conditions)):\n",
        "                    for j in range(i+1, len(conditions)):\n",
        "                        cond1, cond2 = conditions[i], conditions[j]\n",
        "                        p_val = posthoc.loc[cond1, cond2]\n",
        "                        statistical_results.append({\n",
        "                            'feature': feature,\n",
        "                            'test_method': 'ANOVA-TUKEY',\n",
        "                            'condition1': cond1,\n",
        "                            'condition2': cond2,\n",
        "                            'p_value': p_val,\n",
        "                            'significance': '***' if p_val < 0.001 else '**' if p_val < 0.01 else '*' if p_val < 0.05 else ''\n",
        "                        })\n",
        "            elif selected_test == 'kruskal':\n",
        "                _, p_value = stats.kruskal(*valid_groups)\n",
        "                posthoc = sp.posthoc_dunn(features_df, val_col=feature, group_col='condition', p_adjust='bonferroni')\n",
        "                for i in range(len(conditions)):\n",
        "                    for j in range(i+1, len(conditions)):\n",
        "                        cond1, cond2 = conditions[i], conditions[j]\n",
        "                        p_val = posthoc.loc[cond1, cond2]\n",
        "                        statistical_results.append({\n",
        "                            'feature': feature,\n",
        "                            'test_method': 'KRUSKAL-DUNN',\n",
        "                            'condition1': cond1,\n",
        "                            'condition2': cond2,\n",
        "                            'p_value': p_val,\n",
        "                            'significance': '***' if p_val < 0.001 else '**' if p_val < 0.01 else '*' if p_val < 0.05 else ''\n",
        "                        })\n",
        "        except Exception as e:\n",
        "            print(f\"Statistical test failed for {feature} ({selected_test}): {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    return pd.DataFrame(statistical_results)\n",
        "\n",
        "def generate_plots(features_df, stats_df, color_palette):\n",
        "    print(\"Generating plots...\")\n",
        "    plt.rcParams.update({\n",
        "        'font.size': 12,\n",
        "        'axes.titlesize': 14,\n",
        "        'axes.labelsize': 12,\n",
        "        'xtick.labelsize': 10,\n",
        "        'ytick.labelsize': 10,\n",
        "        'figure.dpi': 300,\n",
        "        'savefig.dpi': 300,\n",
        "        'figure.constrained_layout.use': True\n",
        "    })\n",
        "\n",
        "    features = ['mean_speed', 'directionality', 'asphericity', 'duration',\n",
        "               'mean_square_displacement', 'mean_displacement',\n",
        "               'track_straightness', 'mean_turning_angle']\n",
        "\n",
        "    # Plots without stats\n",
        "    for feat in features:\n",
        "        fig, ax = plt.subplots(figsize=(8, 7))\n",
        "        sns.boxplot(x='condition', y=feat, data=features_df, palette=color_palette, ax=ax)\n",
        "        sns.stripplot(x='condition', y=feat, data=features_df, palette=color_palette,\n",
        "                     edgecolor='black', linewidth=0.5, size=4, alpha=0.7, ax=ax)\n",
        "        ax.set_xlabel('Condition')\n",
        "        ax.set_ylabel(' '.join(word.capitalize() for word in feat.split('_')))\n",
        "        ax.set_title(' '.join(word.capitalize() for word in feat.split('_')), fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        save_plot(fig, f'{feat}_without_stats.png', 'Without Stats')\n",
        "\n",
        "    # Plots with stats\n",
        "    if not stats_df.empty and 'significance' in stats_df.columns:\n",
        "        for feat in features:\n",
        "            fig, ax = plt.subplots(figsize=(10, 9))\n",
        "            sns.boxplot(x='condition', y=feat, data=features_df, palette=color_palette, ax=ax)\n",
        "            sns.stripplot(x='condition', y=feat, data=features_df, palette=color_palette,\n",
        "                         edgecolor='black', linewidth=0.5, size=4, alpha=0.7, ax=ax)\n",
        "\n",
        "            ax.set_xlabel('Condition')\n",
        "            ax.set_ylabel(' '.join(word.capitalize() for word in feat.split('_')))\n",
        "\n",
        "            ymin, ymax = ax.get_ylim()\n",
        "            y_pad = (ymax - ymin) * 0.4\n",
        "            ax.set_ylim(ymin, ymax + y_pad)\n",
        "\n",
        "            pairs = [(c1, c2) for i, c1 in enumerate(color_palette) for j, c2 in enumerate(color_palette) if i < j]\n",
        "            y = ymax + (ymax - ymin) * 0.1\n",
        "            for c1, c2 in pairs:\n",
        "                row = stats_df.query(\"feature == @feat and condition1 == @c1 and condition2 == @c2\")\n",
        "                if not row.empty and row['significance'].iloc[0]:\n",
        "                    x1 = list(color_palette).index(c1)\n",
        "                    x2 = list(color_palette).index(c2)\n",
        "                    stars = row['significance'].iloc[0]\n",
        "                    ax.plot([x1, x1, x2, x2], [y, y + 0.05*(ymax - ymin), y + 0.05*(ymax - ymin), y], 'k-')\n",
        "                    ax.text((x1 + x2)/2, y + 0.06*(ymax - ymin), stars, ha='center', va='bottom')\n",
        "                    y += 0.08 * (ymax - ymin)\n",
        "\n",
        "            ax.set_title(f\"{' '.join(word.capitalize() for word in feat.split('_'))} (With Stats)\", fontweight='bold')\n",
        "            plt.tight_layout()\n",
        "            save_plot(fig, f'{feat}_with_stats.png', 'With Stats')\n",
        "\n",
        "    # Instantaneous speed plot\n",
        "    fig, ax = plt.subplots(figsize=(12,8), dpi=300)\n",
        "    for cond, color in color_palette.items():\n",
        "        subset = features_df[features_df['condition']==cond]\n",
        "        times = np.concatenate(subset['times'].tolist())\n",
        "        speeds = np.concatenate(subset['step_speeds'].tolist())\n",
        "        df = pd.DataFrame({'time':times,'speed':speeds}).groupby('time')['speed'].mean().reset_index()\n",
        "        if len(df)>1:\n",
        "            sm = gaussian_filter1d(df['speed'], sigma=1.5)\n",
        "            ax.plot(df['time'], sm, linewidth=2.5, color=color, alpha=1.0, label=cond)\n",
        "    ymin, ymax = ax.get_ylim()\n",
        "    pad = (ymax-ymin)*0.2\n",
        "    ax.set_ylim(max(0,ymin-pad), ymax+pad)\n",
        "    ax.set_xlabel('Time (frames)')\n",
        "    ax.set_ylabel('Speed (μm/min)')\n",
        "    ax.set_title('Instantaneous Speed vs Time')\n",
        "    ax.legend(list(color_palette.keys()), bbox_to_anchor=(1.05,1), loc='upper left')\n",
        "    save_plot(fig, 'instantaneous_speed_vs_time.png','Without Stats')\n",
        "\n",
        "    # Directionality polar plot\n",
        "    fig = plt.figure(figsize=(10,8))\n",
        "    ax = fig.add_subplot(111, projection='polar')\n",
        "    ax.set_theta_zero_location('E')\n",
        "    ax.set_theta_direction(-1)\n",
        "    ax.set_title('Cell Migration Directionality', pad=20)\n",
        "    for cond, color in color_palette.items():\n",
        "        angles = [r for r in features_df[features_df['condition']==cond]['displacement_angle'] if not np.isnan(r)]\n",
        "        if angles:\n",
        "            hist, bins = np.histogram(angles, bins=24, range=(-np.pi, np.pi))\n",
        "            centers = (bins[:-1]+bins[1:])/2\n",
        "            hist = hist / hist.sum() if hist.sum()>0 else hist\n",
        "            data_angles = np.concatenate([centers, [centers[0]]])\n",
        "            data_hist = np.concatenate([hist, [hist[0]]])\n",
        "            ax.plot(data_angles, data_hist, 'o-', label=cond)\n",
        "    ax.legend(bbox_to_anchor=(1.15,1), loc='upper left')\n",
        "    save_plot(fig, 'directionality_polar_plot.png', 'Without Stats')\n",
        "\n",
        "    # Filled-rose plot\n",
        "    def rose_plot(ax, angles, color, n_bins=24):\n",
        "        hist, bins = np.histogram(angles, bins=n_bins, range=(-np.pi,np.pi))\n",
        "        widths = np.diff(bins)\n",
        "        ax.bar(bins[:-1], hist, width=widths, bottom=0, color=color, alpha=0.7, edgecolor='black', align='edge')\n",
        "\n",
        "    fig = plt.figure(figsize=(4*len(color_palette),4), dpi=300)\n",
        "    for i,(cond,color) in enumerate(color_palette.items(),1):\n",
        "        ax = fig.add_subplot(1,len(color_palette),i, projection='polar')\n",
        "        ax.set_theta_zero_location('E')\n",
        "        ax.set_theta_direction(-1)\n",
        "        angles = features_df.query(\"condition==@cond\")['displacement_angle'].dropna().values\n",
        "        rose_plot(ax, angles, color)\n",
        "        ax.set_title(cond, pad=20)\n",
        "    save_plot(fig, 'directionality_rose_plot.png','Without Stats')\n",
        "\n",
        "# ==================== MAIN EXECUTION ====================\n",
        "def run_analysis(b):\n",
        "    clear_output()\n",
        "    print(\"Setting up analysis...\")\n",
        "\n",
        "    # Reset output folder\n",
        "    shutil.rmtree(output_dir, ignore_errors=True)\n",
        "    os.makedirs(os.path.join(output_dir, \"Without Stats\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, \"With Stats\"), exist_ok=True)\n",
        "\n",
        "    # Process selected files\n",
        "    CONDITION_GROUPS = {}\n",
        "    for name_widget, file_widget in condition_widgets:\n",
        "        condition_name = name_widget.value.strip()\n",
        "        selected_files = list(file_widget.value)\n",
        "\n",
        "        if not condition_name:\n",
        "            print(f\"Warning: Empty condition name skipped\")\n",
        "            continue\n",
        "\n",
        "        if selected_files:\n",
        "            CONDITION_GROUPS[condition_name] = selected_files\n",
        "        else:\n",
        "            print(f\"Warning: No file selected for {condition_name}\")\n",
        "\n",
        "    if not CONDITION_GROUPS:\n",
        "        print(\"Error: No valid conditions with files provided\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nConditions to analyze:\")\n",
        "    for cond, files_list in CONDITION_GROUPS.items():\n",
        "        print(f\"- {cond}: {files_list}\")\n",
        "\n",
        "    # Run analysis pipeline\n",
        "    STAT_METHOD = 'auto'\n",
        "\n",
        "    # Verify inputs\n",
        "    all_files = [f for fl in CONDITION_GROUPS.values() for f in fl]\n",
        "    missing = [f for f in all_files if not os.path.exists(os.path.join(data_dir, f))]\n",
        "    if missing:\n",
        "        raise FileNotFoundError(f\"Missing: {missing}\")\n",
        "\n",
        "    # Compute features\n",
        "    all_feats = []\n",
        "    for cond, files_list in CONDITION_GROUPS.items():\n",
        "        for f in files_list:\n",
        "            df = pd.read_csv(os.path.join(data_dir, f), low_memory=False)\n",
        "            df.columns = df.columns.str.strip()\n",
        "            df['condition'] = cond\n",
        "            df['TRACK_ID'] = pd.to_numeric(df['TRACK_ID'], errors='coerce').dropna().astype(int)\n",
        "            for tid in df['TRACK_ID'].unique():\n",
        "                feats = compute_track_features(df[df['TRACK_ID'] == tid])\n",
        "                if feats:\n",
        "                    all_feats.append(feats)\n",
        "\n",
        "    features_df = pd.DataFrame(all_feats)\n",
        "    features_df.to_csv(os.path.join(output_dir, 'track_features.csv'), index=False)\n",
        "\n",
        "    # Only run stats if >1 condition\n",
        "    stats_df = run_statistical_tests(features_df, STAT_METHOD) if len(CONDITION_GROUPS) > 1 else pd.DataFrame()\n",
        "    stats_df.to_csv(os.path.join(output_dir, 'statistical_results.csv'), index=False)\n",
        "\n",
        "    # Generate results\n",
        "    conds = list(CONDITION_GROUPS.keys())\n",
        "    cmap = plt.cm.tab20(np.linspace(0, 1, len(conds)))\n",
        "    palette = {conds[i]: cmap[i] for i in range(len(conds))}\n",
        "\n",
        "    generate_plots(features_df, stats_df, palette)\n",
        "    create_instantaneous_speed_movie(features_df, palette, output_dir)\n",
        "    create_directionality_movie(features_df, palette, output_dir)\n",
        "\n",
        "    # Provide download link\n",
        "    print(\"\\nAnalysis complete! Download results:\")\n",
        "    !zip -r /content/results.zip /content/output\n",
        "    files.download('/content/results.zip')\n",
        "\n",
        "\n",
        "run_btn.on_click(run_analysis)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######################## COMPLETE CELL MIGRATION ANALYSIS FOR EQUAL NUMBER OF SPOTS ########################\n",
        "print(\"Starting interactive cell migration analysis...\")\n",
        "\n",
        "# Install required packages\n",
        "!pip install -q umap-learn seaborn>=0.12 scikit-posthocs ipywidgets\n",
        "!apt-get install -qq ffmpeg > /dev/null\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "import scikit_posthocs as sp\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "import warnings\n",
        "from google.colab import files\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration\n",
        "data_dir = '/content'\n",
        "output_dir = '/content/output'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ==================== INTERACTIVE SETUP ====================\n",
        "print(\"\\n=== Condition Setup ===\")\n",
        "print(\"1. Specify number of experimental conditions\")\n",
        "print(\"2. Name each condition\")\n",
        "print(\"3. Select CSV files for each condition from uploaded files\\n\")\n",
        "\n",
        "# Get list of available CSV files\n",
        "available_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
        "\n",
        "# Widget for condition setup\n",
        "condition_count = widgets.IntText(\n",
        "    value=min(3, len(available_files)) if available_files else 1,\n",
        "    description='Number of conditions:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "condition_widgets = []\n",
        "generate_btn = widgets.Button(description=\"Generate Input Fields\")\n",
        "run_btn = widgets.Button(description=\"Run Analysis\", button_style='success')\n",
        "\n",
        "def generate_fields(b):\n",
        "    global condition_widgets\n",
        "    clear_output()\n",
        "    condition_widgets = []\n",
        "\n",
        "    display(condition_count)\n",
        "\n",
        "    for i in range(condition_count.value):\n",
        "        name_widget = widgets.Text(\n",
        "            description=f'Condition {i+1} Name:',\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "\n",
        "        # Create dropdown with available CSV files\n",
        "        file_widget = widgets.SelectMultiple(\n",
        "            options=available_files,\n",
        "            description=f'Select CSV(s) for Condition {i+1}:',\n",
        "            disabled=False,\n",
        "            style={'description_width': 'initial'},\n",
        "            layout=widgets.Layout(width='50%')  # optional, makes it wider\n",
        "        )\n",
        "\n",
        "\n",
        "        condition_widgets.append((name_widget, file_widget))\n",
        "        display(name_widget, file_widget)\n",
        "\n",
        "    display(run_btn)\n",
        "\n",
        "generate_btn.on_click(generate_fields)\n",
        "display(condition_count, generate_btn)\n",
        "\n",
        "# ==================== ANALYSIS FUNCTIONS ====================\n",
        "def save_plot(fig, name, subfolder):\n",
        "    if not hasattr(fig, 'savefig'):\n",
        "        fig = plt.gcf()\n",
        "    path = os.path.join(output_dir, subfolder, name)\n",
        "    fig.savefig(path, bbox_inches='tight', dpi=300)\n",
        "    plt.close(fig)\n",
        "\n",
        "def compute_track_features(track_df):\n",
        "    track_df = track_df.sort_values('FRAME')\n",
        "    if len(track_df) < 2:\n",
        "        return None\n",
        "\n",
        "    # Clean and convert numeric columns\n",
        "    for col in ['POSITION_X','POSITION_Y','POSITION_Z','FRAME']:\n",
        "        if col in track_df.columns:\n",
        "            track_df[col] = pd.to_numeric(track_df[col], errors='coerce')\n",
        "            if col in ['POSITION_X','POSITION_Y','FRAME']:\n",
        "                track_df = track_df.dropna(subset=[col])\n",
        "    if len(track_df) < 2:\n",
        "        return None\n",
        "\n",
        "    # Position and time data\n",
        "    x = track_df['POSITION_X'].values.astype(float)\n",
        "    y = track_df['POSITION_Y'].values.astype(float)\n",
        "    z = track_df.get('POSITION_Z', np.zeros(len(x))).astype(float)\n",
        "    t = track_df['FRAME'].values.astype(float)\n",
        "\n",
        "    # Calculate displacements and speeds\n",
        "    delta_x = np.diff(x)\n",
        "    delta_y = np.diff(y)\n",
        "    delta_z = np.diff(z)\n",
        "    delta_t = np.diff(t).astype(float)\n",
        "    delta_t[delta_t == 0] = np.nan\n",
        "\n",
        "    step_dist = np.sqrt(delta_x**2 + delta_y**2 + delta_z**2)\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter('ignore')\n",
        "        step_speed = step_dist / delta_t\n",
        "\n",
        "    valid = ~np.isnan(step_speed)\n",
        "    speeds = step_speed[valid]\n",
        "    if len(speeds)==0:\n",
        "        return None\n",
        "\n",
        "    # Velocity and direction calculations\n",
        "    velocity_vectors = np.column_stack((delta_x, delta_y)) / delta_t[:, None]\n",
        "    step_angles = np.arctan2(velocity_vectors[:, 1], velocity_vectors[:, 0])\n",
        "    turning_angles = np.abs(np.diff(step_angles))\n",
        "    turning_angles = np.where(turning_angles > np.pi, 2*np.pi - turning_angles, turning_angles)\n",
        "\n",
        "    # Core metrics\n",
        "    mean_speed = np.nanmean(speeds)\n",
        "    displacement = np.sqrt((x[-1]-x[0])**2 + (y[-1]-y[0])**2)\n",
        "    total_distance = np.nansum(step_dist[valid])\n",
        "    directionality = displacement / total_distance if total_distance > 0 else np.nan\n",
        "\n",
        "    # MSD calculation\n",
        "    time_lags = np.unique(t[1:][valid] - t[0])\n",
        "    msd = np.zeros(len(time_lags))\n",
        "    for i, lag in enumerate(time_lags):\n",
        "        time_pairs = t[:, None] - t\n",
        "        mask = (time_pairs == lag) & (np.triu(np.ones_like(time_pairs, dtype=bool), k=1))\n",
        "        dx = x[:, None] - x\n",
        "        dy = y[:, None] - y\n",
        "        diffs = (dx**2 + dy**2)[mask]\n",
        "        msd[i] = np.mean(diffs) if len(diffs) > 0 else np.nan\n",
        "\n",
        "    # Shape metrics\n",
        "    xy = np.column_stack((x, y))\n",
        "    if len(xy) > 1:\n",
        "        cov = np.cov(xy.T)\n",
        "        eigvals = np.linalg.eigvals(cov)\n",
        "        eigvals = sorted(eigvals, reverse=True)\n",
        "        asphericity = (eigvals[0] - eigvals[1])**2 / sum(eigvals)**2 if sum(eigvals) > 0 else np.nan\n",
        "    else:\n",
        "        asphericity = np.nan\n",
        "\n",
        "    # Final displacement angle\n",
        "    dx = x[-1] - x[0]\n",
        "    dy = y[-1] - y[0]\n",
        "    displacement_angle = np.arctan2(dy, dx) if (dx != 0 or dy != 0) else np.nan\n",
        "\n",
        "    return {\n",
        "        'track_id': track_df['TRACK_ID'].iloc[0],\n",
        "        'condition': track_df['condition'].iloc[0],\n",
        "        'mean_speed': mean_speed,\n",
        "        'displacement': displacement,\n",
        "        'total_distance': total_distance,\n",
        "        'directionality': directionality,\n",
        "        'asphericity': asphericity,\n",
        "        'duration': t[-1] - t[0],\n",
        "        'mean_x': np.mean(x),\n",
        "        'mean_y': np.mean(y),\n",
        "        'step_speeds': speeds,\n",
        "        'step_angles': step_angles,\n",
        "        'turning_angles': turning_angles,\n",
        "        'times': t[1:][valid],\n",
        "        'velocity_vectors': velocity_vectors,\n",
        "        'displacement_angle': displacement_angle,\n",
        "        'mean_square_displacement': np.nanmean(msd),\n",
        "        'mean_displacement': np.nanmean(step_dist[valid]),\n",
        "        'track_straightness': directionality,\n",
        "        'mean_turning_angle': np.nanmean(turning_angles) if len(turning_angles) > 0 else np.nan\n",
        "    }\n",
        "\n",
        "def create_instantaneous_speed_movie(features_df, color_palette, output_dir):\n",
        "    print(\"Creating speed movie...\")\n",
        "    condition_data = {}\n",
        "    max_speed, min_speed = 0, float('inf')\n",
        "\n",
        "    for condition in color_palette:\n",
        "        all_times, all_speeds = [], []\n",
        "        for _, row in features_df[features_df['condition'] == condition].iterrows():\n",
        "            all_times.extend(row['times'])\n",
        "            all_speeds.extend(row['step_speeds'])\n",
        "\n",
        "        df = pd.DataFrame({'time': all_times, 'speed': all_speeds})\n",
        "        df = df.groupby('time')['speed'].mean().reset_index()\n",
        "        df['smoothed_speed'] = gaussian_filter1d(df['speed'], sigma=1.5) if len(df) > 1 else df['speed']\n",
        "        condition_data[condition] = df\n",
        "        max_speed = max(max_speed, df['speed'].max())\n",
        "        min_speed = min(min_speed, df['speed'].min())\n",
        "\n",
        "    all_times = np.concatenate([df['time'] for df in condition_data.values()])\n",
        "    time_points = np.linspace(min(all_times), max(all_times), 150)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 8), dpi=300)\n",
        "    plt.xlabel('Time (frames)')\n",
        "    plt.ylabel('Speed (μm/min)')\n",
        "    plt.title('Instantaneous Speed vs Time')\n",
        "\n",
        "    raw_lines, smooth_lines, markers = {}, {}, {}\n",
        "    for cond, color in color_palette.items():\n",
        "        raw_lines[cond], = ax.plot([], [], lw=1.5, color=color, alpha=0.25)\n",
        "        smooth_lines[cond], = ax.plot([], [], lw=2.5, color=color, alpha=0.9, label=cond)\n",
        "        markers[cond], = ax.plot([], [], 'o', color=color, markersize=8)\n",
        "\n",
        "    y_padding = (max_speed - min_speed) * 0.2\n",
        "    ax.set_ylim(max(0, min_speed - y_padding), max_speed + y_padding)\n",
        "    ax.set_xlim(min(all_times), max(all_times))\n",
        "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "    def animate(i):\n",
        "        current_time = time_points[i]\n",
        "        for cond, df in condition_data.items():\n",
        "            mask = df['time'] <= current_time\n",
        "            times = df['time'][mask]\n",
        "            if len(times) > 0:\n",
        "                raw_lines[cond].set_data(times, df['speed'][mask])\n",
        "                smooth_lines[cond].set_data(times, df['smoothed_speed'][mask])\n",
        "                if times.iloc[-1] >= current_time:\n",
        "                    markers[cond].set_data([current_time], [df['smoothed_speed'][mask].iloc[-1]])\n",
        "        return list(raw_lines.values()) + list(smooth_lines.values()) + list(markers.values())\n",
        "\n",
        "    ani = animation.FuncAnimation(fig, animate, frames=len(time_points), interval=30, blit=True)\n",
        "    output_path = os.path.join(output_dir, 'Without Stats', 'instantaneous_speed_movie.mp4')\n",
        "    ani.save(output_path, writer='ffmpeg', dpi=300, bitrate=5000)\n",
        "    plt.close()\n",
        "\n",
        "def create_directionality_movie(features_df, palette, output_dir):\n",
        "    print(\"Creating directionality movie...\")\n",
        "    def rose_plot(ax, angles, color, n_bins=24):\n",
        "        hist, bins = np.histogram(angles, bins=n_bins, range=(-np.pi,np.pi))\n",
        "        widths = np.diff(bins)\n",
        "        ax.bar(bins[:-1], hist, width=widths, bottom=0, color=color, alpha=0.7, edgecolor='black', align='edge')\n",
        "\n",
        "    cond_data = {}\n",
        "    for cond in palette:\n",
        "        times, angs = [], []\n",
        "        for _, row in features_df[features_df['condition']==cond].iterrows():\n",
        "            if not np.isnan(row['displacement_angle']):\n",
        "                times.append(row['times'][-1])\n",
        "                angs.append(row['displacement_angle'])\n",
        "        cond_data[cond] = pd.DataFrame({'time':times,'angle':angs})\n",
        "\n",
        "    all_t = np.unique(np.concatenate([d['time'] for d in cond_data.values()]))\n",
        "    time_pts = np.linspace(all_t.min(), all_t.max(), 100)\n",
        "\n",
        "    fig = plt.figure(figsize=(4*len(palette),4), dpi=300)\n",
        "    axes = [fig.add_subplot(1,len(palette),i+1, projection='polar') for i in range(len(palette))]\n",
        "    for ax in axes:\n",
        "        ax.set_theta_zero_location('E')\n",
        "        ax.set_theta_direction(-1)\n",
        "\n",
        "    def animate(i):\n",
        "        t = time_pts[i]\n",
        "        for ax,(cond,color) in zip(axes, palette.items()):\n",
        "            ax.clear()\n",
        "            ax.set_theta_zero_location('E')\n",
        "            ax.set_theta_direction(-1)\n",
        "            ax.set_title(cond, pad=20)\n",
        "            past = cond_data[cond][cond_data[cond]['time']<=t]\n",
        "            if not past.empty:\n",
        "                rose_plot(ax, past['angle'].values, color)\n",
        "        return axes\n",
        "\n",
        "    ani = animation.FuncAnimation(fig, animate, frames=len(time_pts), interval=100, blit=False)\n",
        "    out = os.path.join(output_dir,'Without Stats','directionality_rose_movie.mp4')\n",
        "    ani.save(out, writer='ffmpeg', dpi=300, bitrate=5000)\n",
        "    plt.close(fig)\n",
        "\n",
        "def run_statistical_tests(features_df, test_method='auto'):\n",
        "    print(\"Running statistical tests...\")\n",
        "    statistical_results = []\n",
        "    features_to_analyze = ['mean_speed', 'directionality', 'asphericity', 'duration',\n",
        "                         'mean_square_displacement', 'mean_displacement',\n",
        "                         'track_straightness', 'mean_turning_angle']\n",
        "    conditions = features_df['condition'].unique()\n",
        "\n",
        "    if len(conditions) < 2:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    for feature in features_to_analyze:\n",
        "        groups = [features_df[features_df['condition'] == c][feature].dropna().values for c in conditions]\n",
        "        valid_groups = [g for g in groups if len(g) > 0]\n",
        "        if len(valid_groups) < 2:\n",
        "            continue\n",
        "\n",
        "        selected_test = test_method\n",
        "        if test_method == 'auto':\n",
        "            normal = all(len(g) > 3 and stats.shapiro(g)[1] > 0.05 for g in valid_groups)\n",
        "            equal_var = stats.levene(*valid_groups).pvalue > 0.05 if normal else False\n",
        "\n",
        "            if len(conditions) == 2:\n",
        "                selected_test = 't-test' if (normal and equal_var) else 'welch' if normal else 'mannwhitney'\n",
        "            else:\n",
        "                selected_test = 'anova' if (normal and equal_var) else 'kruskal'\n",
        "\n",
        "        try:\n",
        "            if selected_test in ['t-test', 'welch']:\n",
        "                result = stats.ttest_ind(*valid_groups[:2], equal_var=(selected_test == 't-test'))\n",
        "                statistical_results.append({\n",
        "                    'feature': feature,\n",
        "                    'test_method': selected_test.upper(),\n",
        "                    'condition1': conditions[0],\n",
        "                    'condition2': conditions[1],\n",
        "                    'p_value': result.pvalue,\n",
        "                    'significance': '***' if result.pvalue < 0.001 else '**' if result.pvalue < 0.01 else '*' if result.pvalue < 0.05 else ''\n",
        "                })\n",
        "            elif selected_test == 'mannwhitney':\n",
        "                result = stats.mannwhitneyu(*valid_groups[:2])\n",
        "                statistical_results.append({\n",
        "                    'feature': feature,\n",
        "                    'test_method': selected_test.upper(),\n",
        "                    'condition1': conditions[0],\n",
        "                    'condition2': conditions[1],\n",
        "                    'p_value': result.pvalue,\n",
        "                    'significance': '***' if result.pvalue < 0.001 else '**' if result.pvalue < 0.01 else '*' if result.pvalue < 0.05 else ''\n",
        "                })\n",
        "            elif selected_test == 'anova':\n",
        "                _, p_value = stats.f_oneway(*valid_groups)\n",
        "                posthoc = sp.posthoc_tukey(features_df, val_col=feature, group_col='condition')\n",
        "                for i in range(len(conditions)):\n",
        "                    for j in range(i+1, len(conditions)):\n",
        "                        cond1, cond2 = conditions[i], conditions[j]\n",
        "                        p_val = posthoc.loc[cond1, cond2]\n",
        "                        statistical_results.append({\n",
        "                            'feature': feature,\n",
        "                            'test_method': 'ANOVA-TUKEY',\n",
        "                            'condition1': cond1,\n",
        "                            'condition2': cond2,\n",
        "                            'p_value': p_val,\n",
        "                            'significance': '***' if p_val < 0.001 else '**' if p_val < 0.01 else '*' if p_val < 0.05 else ''\n",
        "                        })\n",
        "            elif selected_test == 'kruskal':\n",
        "                _, p_value = stats.kruskal(*valid_groups)\n",
        "                posthoc = sp.posthoc_dunn(features_df, val_col=feature, group_col='condition', p_adjust='bonferroni')\n",
        "                for i in range(len(conditions)):\n",
        "                    for j in range(i+1, len(conditions)):\n",
        "                        cond1, cond2 = conditions[i], conditions[j]\n",
        "                        p_val = posthoc.loc[cond1, cond2]\n",
        "                        statistical_results.append({\n",
        "                            'feature': feature,\n",
        "                            'test_method': 'KRUSKAL-DUNN',\n",
        "                            'condition1': cond1,\n",
        "                            'condition2': cond2,\n",
        "                            'p_value': p_val,\n",
        "                            'significance': '***' if p_val < 0.001 else '**' if p_val < 0.01 else '*' if p_val < 0.05 else ''\n",
        "                        })\n",
        "        except Exception as e:\n",
        "            print(f\"Statistical test failed for {feature} ({selected_test}): {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    return pd.DataFrame(statistical_results)\n",
        "\n",
        "def generate_plots(features_df, stats_df, color_palette):\n",
        "    print(\"Generating plots...\")\n",
        "    plt.rcParams.update({\n",
        "        'font.size': 12,\n",
        "        'axes.titlesize': 14,\n",
        "        'axes.labelsize': 12,\n",
        "        'xtick.labelsize': 10,\n",
        "        'ytick.labelsize': 10,\n",
        "        'figure.dpi': 300,\n",
        "        'savefig.dpi': 300,\n",
        "        'figure.constrained_layout.use': True\n",
        "    })\n",
        "\n",
        "    features = ['mean_speed', 'directionality', 'asphericity', 'duration',\n",
        "               'mean_square_displacement', 'mean_displacement',\n",
        "               'track_straightness', 'mean_turning_angle']\n",
        "\n",
        "    # Plots without stats\n",
        "    for feat in features:\n",
        "        fig, ax = plt.subplots(figsize=(8, 7))\n",
        "        sns.boxplot(x='condition', y=feat, data=features_df, palette=color_palette, ax=ax)\n",
        "        sns.stripplot(x='condition', y=feat, data=features_df, palette=color_palette,\n",
        "                     edgecolor='black', linewidth=0.5, size=4, alpha=0.7, ax=ax)\n",
        "        ax.set_xlabel('Condition')\n",
        "        ax.set_ylabel(' '.join(word.capitalize() for word in feat.split('_')))\n",
        "        ax.set_title(' '.join(word.capitalize() for word in feat.split('_')), fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        save_plot(fig, f'{feat}_without_stats.png', 'Without Stats')\n",
        "\n",
        "    # Plots with stats\n",
        "    if not stats_df.empty and 'significance' in stats_df.columns:\n",
        "        for feat in features:\n",
        "            fig, ax = plt.subplots(figsize=(10, 9))\n",
        "            sns.boxplot(x='condition', y=feat, data=features_df, palette=color_palette, ax=ax)\n",
        "            sns.stripplot(x='condition', y=feat, data=features_df, palette=color_palette,\n",
        "                         edgecolor='black', linewidth=0.5, size=4, alpha=0.7, ax=ax)\n",
        "\n",
        "            ax.set_xlabel('Condition')\n",
        "            ax.set_ylabel(' '.join(word.capitalize() for word in feat.split('_')))\n",
        "\n",
        "            ymin, ymax = ax.get_ylim()\n",
        "            y_pad = (ymax - ymin) * 0.4\n",
        "            ax.set_ylim(ymin, ymax + y_pad)\n",
        "\n",
        "            pairs = [(c1, c2) for i, c1 in enumerate(color_palette) for j, c2 in enumerate(color_palette) if i < j]\n",
        "            y = ymax + (ymax - ymin) * 0.1\n",
        "            for c1, c2 in pairs:\n",
        "                row = stats_df.query(\"feature == @feat and condition1 == @c1 and condition2 == @c2\")\n",
        "                if not row.empty and row['significance'].iloc[0]:\n",
        "                    x1 = list(color_palette).index(c1)\n",
        "                    x2 = list(color_palette).index(c2)\n",
        "                    stars = row['significance'].iloc[0]\n",
        "                    ax.plot([x1, x1, x2, x2], [y, y + 0.05*(ymax - ymin), y + 0.05*(ymax - ymin), y], 'k-')\n",
        "                    ax.text((x1 + x2)/2, y + 0.06*(ymax - ymin), stars, ha='center', va='bottom')\n",
        "                    y += 0.08 * (ymax - ymin)\n",
        "\n",
        "            ax.set_title(f\"{' '.join(word.capitalize() for word in feat.split('_'))} (With Stats)\", fontweight='bold')\n",
        "            plt.tight_layout()\n",
        "            save_plot(fig, f'{feat}_with_stats.png', 'With Stats')\n",
        "\n",
        "    # Instantaneous speed plot\n",
        "    fig, ax = plt.subplots(figsize=(12,8), dpi=300)\n",
        "    for cond, color in color_palette.items():\n",
        "        subset = features_df[features_df['condition']==cond]\n",
        "        times = np.concatenate(subset['times'].tolist())\n",
        "        speeds = np.concatenate(subset['step_speeds'].tolist())\n",
        "        df = pd.DataFrame({'time':times,'speed':speeds}).groupby('time')['speed'].mean().reset_index()\n",
        "        if len(df)>1:\n",
        "            sm = gaussian_filter1d(df['speed'], sigma=1.5)\n",
        "            ax.plot(df['time'], sm, linewidth=2.5, color=color, alpha=1.0, label=cond)\n",
        "    ymin, ymax = ax.get_ylim()\n",
        "    pad = (ymax-ymin)*0.2\n",
        "    ax.set_ylim(max(0,ymin-pad), ymax+pad)\n",
        "    ax.set_xlabel('Time (frames)')\n",
        "    ax.set_ylabel('Speed (μm/min)')\n",
        "    ax.set_title('Instantaneous Speed vs Time')\n",
        "    ax.legend(list(color_palette.keys()), bbox_to_anchor=(1.05,1), loc='upper left')\n",
        "    save_plot(fig, 'instantaneous_speed_vs_time.png','Without Stats')\n",
        "\n",
        "    # Directionality polar plot\n",
        "    fig = plt.figure(figsize=(10,8))\n",
        "    ax = fig.add_subplot(111, projection='polar')\n",
        "    ax.set_theta_zero_location('E')\n",
        "    ax.set_theta_direction(-1)\n",
        "    ax.set_title('Cell Migration Directionality', pad=20)\n",
        "    for cond, color in color_palette.items():\n",
        "        angles = [r for r in features_df[features_df['condition']==cond]['displacement_angle'] if not np.isnan(r)]\n",
        "        if angles:\n",
        "            hist, bins = np.histogram(angles, bins=24, range=(-np.pi, np.pi))\n",
        "            centers = (bins[:-1]+bins[1:])/2\n",
        "            hist = hist / hist.sum() if hist.sum()>0 else hist\n",
        "            data_angles = np.concatenate([centers, [centers[0]]])\n",
        "            data_hist = np.concatenate([hist, [hist[0]]])\n",
        "            ax.plot(data_angles, data_hist, 'o-', label=cond)\n",
        "    ax.legend(bbox_to_anchor=(1.15,1), loc='upper left')\n",
        "    save_plot(fig, 'directionality_polar_plot.png', 'Without Stats')\n",
        "\n",
        "    # Filled-rose plot\n",
        "    def rose_plot(ax, angles, color, n_bins=24):\n",
        "        hist, bins = np.histogram(angles, bins=n_bins, range=(-np.pi,np.pi))\n",
        "        widths = np.diff(bins)\n",
        "        ax.bar(bins[:-1], hist, width=widths, bottom=0, color=color, alpha=0.7, edgecolor='black', align='edge')\n",
        "\n",
        "    fig = plt.figure(figsize=(4*len(color_palette),4), dpi=300)\n",
        "    for i,(cond,color) in enumerate(color_palette.items(),1):\n",
        "        ax = fig.add_subplot(1,len(color_palette),i, projection='polar')\n",
        "        ax.set_theta_zero_location('E')\n",
        "        ax.set_theta_direction(-1)\n",
        "        angles = features_df.query(\"condition==@cond\")['displacement_angle'].dropna().values\n",
        "        rose_plot(ax, angles, color)\n",
        "        ax.set_title(cond, pad=20)\n",
        "    save_plot(fig, 'directionality_rose_plot.png','Without Stats')\n",
        "\n",
        "# ==================== MAIN EXECUTION ====================\n",
        "def run_analysis(b):\n",
        "    clear_output()\n",
        "    print(\"Setting up analysis...\")\n",
        "\n",
        "    # Reset output folder\n",
        "    shutil.rmtree(output_dir, ignore_errors=True)\n",
        "    os.makedirs(os.path.join(output_dir, \"Without Stats\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, \"With Stats\"), exist_ok=True)\n",
        "\n",
        "    # Process selected files\n",
        "    CONDITION_GROUPS = {}\n",
        "    for name_widget, file_widget in condition_widgets:\n",
        "        condition_name = name_widget.value.strip()\n",
        "        selected_files = list(file_widget.value)\n",
        "\n",
        "        if not condition_name:\n",
        "            print(f\"Warning: Empty condition name skipped\")\n",
        "            continue\n",
        "\n",
        "        if selected_files:\n",
        "            CONDITION_GROUPS[condition_name] = selected_files\n",
        "        else:\n",
        "            print(f\"Warning: No file selected for {condition_name}\")\n",
        "\n",
        "    if not CONDITION_GROUPS:\n",
        "        print(\"Error: No valid conditions with files provided\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nConditions to analyze:\")\n",
        "    for cond, files_list in CONDITION_GROUPS.items():\n",
        "        print(f\"- {cond}: {files_list}\")\n",
        "\n",
        "    # Run analysis pipeline\n",
        "    STAT_METHOD = 'auto'\n",
        "\n",
        "    # Verify inputs\n",
        "    all_files = [f for fl in CONDITION_GROUPS.values() for f in fl]\n",
        "    missing = [f for f in all_files if not os.path.exists(os.path.join(data_dir, f))]\n",
        "    if missing:\n",
        "        raise FileNotFoundError(f\"Missing: {missing}\")\n",
        "\n",
        "    # Compute features\n",
        "    all_feats = []\n",
        "    for cond, files_list in CONDITION_GROUPS.items():\n",
        "        for f in files_list:\n",
        "            df = pd.read_csv(os.path.join(data_dir, f), low_memory=False)\n",
        "            df.columns = df.columns.str.strip()\n",
        "            df['condition'] = cond\n",
        "            df['TRACK_ID'] = pd.to_numeric(df['TRACK_ID'], errors='coerce').dropna().astype(int)\n",
        "            for tid in df['TRACK_ID'].unique():\n",
        "                feats = compute_track_features(df[df['TRACK_ID'] == tid])\n",
        "                if feats:\n",
        "                    all_feats.append(feats)\n",
        "\n",
        "    features_df = pd.DataFrame(all_feats)\n",
        "    # randomly down-sample so each condition has the same number of tracks\n",
        "    min_count = features_df['condition'].value_counts().min()\n",
        "    features_df = (\n",
        "        features_df\n",
        "        .groupby('condition', group_keys=False)\n",
        "        .apply(lambda grp: grp.sample(n=min_count, random_state=42))\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "    features_df.to_csv(os.path.join(output_dir, 'track_features.csv'), index=False)\n",
        "\n",
        "    # Only run stats if >1 condition\n",
        "    stats_df = run_statistical_tests(features_df, STAT_METHOD) if len(CONDITION_GROUPS) > 1 else pd.DataFrame()\n",
        "    stats_df.to_csv(os.path.join(output_dir, 'statistical_results.csv'), index=False)\n",
        "\n",
        "    # Generate results\n",
        "    conds = list(CONDITION_GROUPS.keys())\n",
        "    cmap = plt.cm.tab20(np.linspace(0, 1, len(conds)))\n",
        "    palette = {conds[i]: cmap[i] for i in range(len(conds))}\n",
        "\n",
        "    generate_plots(features_df, stats_df, palette)\n",
        "    create_instantaneous_speed_movie(features_df, palette, output_dir)\n",
        "    create_directionality_movie(features_df, palette, output_dir)\n",
        "\n",
        "    # Provide download link\n",
        "    print(\"\\nAnalysis complete! Download results:\")\n",
        "    !zip -r /content/results.zip /content/output\n",
        "    files.download('/content/results.zip')\n",
        "\n",
        "\n",
        "run_btn.on_click(run_analysis)"
      ],
      "metadata": {
        "id": "hEVbEmK3wbNE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}